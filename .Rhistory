View(b)
b = unstack(data$feb2016 ~ data$Site)
x =formula(data$feb2016 ~ data$Site)
t = unstack(x)
t = unstack(data, form = x)
feb = c("Site", "feb2016")
feb = data[,feb]
View(feb)
t = unstack(feb)
t
t = unstack(feb$feb2016 ~ feb$Site)
t = unstack(feb, form = feb$feb2016 ~ feb$Site)
View(t)
feb = c("Site", "feb2016")
feb = data[,feb]
feb = unstack(feb, form = feb$feb2016 ~ feb$Site)
fdist = dist(feb)
class(fdist)
fdist = as.dist(fdist)
a = adonis(fdist ~ data$Site, permutations = 99)
fdist
?dist
eo = data$Site[1:72]
eo
a = adonis(fdist ~ eo, permutations = 99)
dim(fdist)
fdist
dim(eo)
class(fdist)
class(eo)
eo = as.vector(eo)
dim(eo)
eo
a = adonis(fdist ~ eo, permutations = 99)
t = subset_samples(data$Site == "EO12", "EO14")
?adonis
eo = as.data.frame(eo)
View(eo)
a = adonis(fdist ~ eo$eo, permutations = 99)
View(eo)
x = aov(formula = data$feb2016 ~ data$Site * data$Treatment)
summary(x)
TukeyHSD(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Site)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Treatment)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Treatment)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Treatment)
summary(x)
x = aov(formula = data$feb2016 ~ data$Site)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Treatment)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Treatment, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Site)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site, DFerror, MSerror)
l
x = aov(formula = data$feb2016 ~ data$Site*data$Treatment)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$feb2016, data$Site*data$Treatment, DFerror, MSerror)
l
View(data)
colnames(data[,8]) = diameter
colnames(data[,8]) = c("diameter")
colnames(data[,8]) = "diameter"
colnames(data[8]) = "diameter"
View(data)
x = aov(formula = data$diameter ~ data$Site * data$Treatment)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$diameter, data$Site, DFerror, MSerror)
l
x = aov(formula = data$diameter ~ data$Site)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$diameter, data$Site, DFerror, MSerror)
l
x = aov(formula = data$diameter ~ data$Treatment)
summary(x)
DFerror = x$df.residual
MSerror = sum(x$residuals^2)/x$df.residual
l = LSD.test(data$diameter, data$Treatment, DFerror, MSerror)
l
x = aov(formula = data$diameter ~ data$Site*data$Treatment)
summary(x)
library(lattice)
sample.data = read.table('C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable1.csv', header=TRUE, sep=",")
sample.data
sample.data = read.csv('C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable1.csv', header=TRUE, sep=",")
sample.data
sample.data = read.csv("C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable1.csv", header=TRUE, sep=",")
library(splus2R)
library(MASS)
library(ifultools)
library(wmtsa)
library(biwavelet)
library(cluster)
library(psych)
library(permute)
library(lattice)
library(vegan)
sample.data = read.csv("C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable1.csv", header=TRUE, sep=",")
getwd()
sample.data = read.csv("C:/Users/jaspkaur/Desktop/MycoOTUtable1.csv", header=TRUE, sep=",")
sample.data = read.csv('C:/Users/jaspkaur/Desktop/MycoOTUtable1.csv', header=TRUE, sep=",")
setwd("C:\\Users\\jass\\Dropbox\\r")
data <- read.csv("C:\\Users\\jass\\Dropbox\\r\\data_em50.csv")
source("C:\\Users\\jaspkaur\\Dropbox\\r\\libraries.r")
setwd = "C:\\Users\\jass\\Dropbox\\7april\\New folder\\"
setwd = "C:\\Users\\jaspkaur\\Dropbox\\7april\\march_2016\\"
sample.data = read.csv("C:\\Users\\jaspkaur\\Dropbox\\MycoOTUtable1.csv", header=TRUE, sep=",")
sample.data = read.csv("C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable1.csv", header=TRUE, sep=",")
sample.data = read.csv("C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable1.csv", header=TRUE)
sample.data = read.csv("C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable.csv", header=TRUE)
View(sample.data)
attach(sample.data)
X = cbind(sample.data[,2:17])
X = na.omit(X)
X.cov = cov(X)
X.cov
X.cor = cor(X)
X.cor
splom(X)
pca.results = prcomp(X, scale=F)
pca.results
summary(pca.results)
screeplot(pca.results, type="lines", main="PCA Scree Plot")
pca.eigenvalues = pca.results$sdev^2
pca.eigenvalues
pca.eigenvalues.sum = sum(pca.eigenvalues)
pca.eigenvalues.sum
pca.loadings = pca.results$rotation
pca.loadings
pca.percentVar = 100*(pca.eigenvalues / sum(pca.eigenvalues))
pca.cumVar = cumsum(pca.percentVar)
pca.percentVar
pca.cumVar
pca.loadings = pca.results$rotation
pca.loadings
pca.loadings.sscp = t(pca.loadings) %*% pca.loadings
pca.loadings.sscp
pca.scores = predict(pca.results)
pca.scores
pca.vectorCorrs = cor(X,pca.scores)
pca.vectorCorrs
xlab.str = paste("PC1 Scores (", as.character(round(pca.percentVar[1],1)),"%)",sep='')
ylab.str = paste("PC2 Scores (", as.character(round(pca.percentVar[2],1)),"%)",sep='')
biplot(pca.results, col=c("red","blue"), xlab=xlab.str,ylab=ylab.str)
xyplot(pca.scores[,2]~pca.scores[,1], pch=19,col="black", xlab=xlab.str,ylab=ylab.str)
?biplot
sample.data = read.csv("C:\\Users\\jaspkaur\\Desktop\\MycoOTUtable.csv", header=TRUE)
sample.data
attach(sample.data)
X = cbind(sample.data[,2:17])
X = na.omit(X)
#X = log(X)
## Examine pairwise relationships among variables
X.cov = cov(X)
X.cov
X.cor = cor(X)
X.cor
x.totVar = sum(diag(X.cov))
x.totVar
splom(X)
## Basic eigenanalysis
eigen.results.cov = eigen(X.cov)
eigen.results.cov
eigen.results.cor = eigen(X.cor)
eigen.results.cor
## Principal components analysis via prcomp()
pca.results = prcomp(X, scale=F)
pca.results
summary(pca.results)
#windows()
screeplot(pca.results, type="lines", main="PCA Scree Plot")
pca.eigenvalues = pca.results$sdev^2
pca.eigenvalues
pca.eigenvalues.sum = sum(pca.eigenvalues)
pca.eigenvalues.sum
pca.percentVar = 100*(pca.eigenvalues / sum(pca.eigenvalues))
pca.cumVar = cumsum(pca.percentVar)
pca.percentVar
pca.cumVar
pca.loadings = pca.results$rotation
pca.loadings
pca.loadings.sscp = t(pca.loadings) %*% pca.loadings
pca.loadings.sscp
pca.scores = predict(pca.results)
pca.scores
pca.vectorCorrs = cor(X,pca.scores)
pca.vectorCorrs
#windows()
splom(pca.scores)
#windows()
xlab.str = paste("PC1 Scores (", as.character(round(pca.percentVar[1],1)),"%)",sep='')
ylab.str = paste("PC2 Scores (", as.character(round(pca.percentVar[2],1)),"%)",sep='')
biplot(pca.results, col=c("red","blue"), xlab=xlab.str,ylab=ylab.str)
#windows()
xyplot(pca.scores[,2]~pca.scores[,1], pch=19,col="black", xlab=xlab.str,ylab=ylab.str)
#windows()
cloud(pca.scores[,3]~pca.scores[,1]*pca.scores[,2], pch=19,col="black",
xlab='PC1 Scores',ylab='PC2 scores',zlab='PC3 scores')
## Principal components analysis via princomp()
pca.results = princomp(X, cor=F, scores=T)         # PCA
pca.results
summary(pca.results, loadings=T)
View(sample.data)
plot(pca.results,
panel = function(x, y, ...) {
points(x, y, ...)
text(x,y,labels=seq_along(x),...) ## You change labels here
}
,
col = as.integer(sample.data$X), pch = 20)
xyplot(pca.scores[,2]~pca.scores[,1], pch=19,col="black", xlab=xlab.str,ylab=ylab.str)
library(devtools)
install_github("ggbiplot", "vqv")
install_github("ggbiplot")
library(devtools)
install_github("ggbiplot", "vqv")
install.packages("Rcpp")
install.packages("Rcpp")
library(Rcpp)
source("C\\Users\\jaspkaur\\Dropbox\\r\\libraries.r")
library(splus2R)
library(MASS)
library(ifultools)
library(wmtsa)
library(biwavelet)
library(cluster)
library(psych)
library(permute)
library(lattice)
library(vegan)
library(ggplot2)
library(gtools)##for reading xls
library(gdata)# for reading xls
library(digest)# for LDA biplots
library(devtools)# for LDA biplots
library(ggord)# for LDA biplots
library(agricolae)
library(reshape2)
library(plyr)
library(ggplot2)
library(phyloseq)
library(bitops)
library(RCurl)
library(jsonlite)
library(jSonarR)
library(RJSONIO)
library(biom)
library(RColorBrewer)
library(aod)
library(grid)
library(survey)
library(scales)
library(MASS)
library("sp", lib.loc="C:/Program Files/R/R-3.2.1/library")
library(splancs)
library(geoR)
library(car)
library(timeDate)
library(timeSeries)
library(fBasics)
library(dunn.test)
library(RandomFields)
library(dunn.test)
install_github("ggbiplot", "vqv")
library(ggbiplot)
trt = sample.data$X
g <- ggbiplot(pca.results, obs.scale = 1, var.scale = 1,
groups = trt, ellipse = TRUE,
circle = TRUE)
g <- ggbiplot(pca.results, obs.scale = 1, var.scale = 1,
groups = trt, ellipse = TRUE,
circle = TRUE)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
pca.results
?ggbiplot
class(trt)
trt
g <- ggbiplot(pca.results)
g
g <- ggbiplot(pca.results, groups = trt)
g
g <- ggbiplot(pca.results,
groups = trt, ellipse = TRUE,
circle = TRUE)
g <- ggbiplot(pca.results,
groups = trt)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
g <- ggbiplot(pca.results,
groups = trt, ellipse = TRUE)
g <- ggbiplot(pca.results,
groups = trt, circle = TRUE)
g
g <- ggbiplot(pca.results,
groups = trt, circle = TRUE)
g <- g + scale_color_discrete(name = '')
g
g <- ggbiplot(pca.results,
groups = trt, circle = TRUE)
g
?cor
?cor.test
temp = read.csv(file = "C:/Users/jaspkaur/Desktop/Book1.csv", header = T)
cor.test(temp)
x = cor.test(temp$diameter, temp$atemp)
x
install.packages("ANCOM")
library(ANCOM)
install.packages("ANCOM")
?model.matrix
?%in%
library(vegan)
library(reshape2)
library(phyloseq)
library(permute)
library(lattice)
library(vegan)
library(reshape2)
library(ggplot2)
library(car)
library(data.table)
library(scales)
library(plyr)
library(agricolae)
?nmds
citation()
library(gdata)
?install.packages
library(pbkrtest)
?PBmodcomp
library(parallel)
?makeCluster
library(readxl)
library(ggplot2)
library(pscl)
library(lme4)
library(dplyr)
library(pbkrtest)
?glmer
library(parallel)
?stopCluster
library(phyloseq)
library(ancom.R)
library(devtools)
install.packages("devtools")
source("https://bioconductor.org/biocLite.R")
biocLite("phyloseq")
install.packages("wmtsa")
install.packages("splus2R")
install.packages("ifultools")
install.packages("MASS")
install.packages("cluster")
install.packages("psych")
install.packages("vegan")
install.packages("biwavelet")
install.packages("devtools")
install.packages("digest")
install.packages("colorspace")
install.packages("aod")
install.packages("survey")
install.packages("scales")
install.packages("splancs")
install.packages("geoR")
install.packages("car")
install.packages("fBasics")
install.packages("timeDate")
install.packages("timeseries")
install.packages("RandomFields")
install.packages("gdata")
install.packages("deldir")
install.packages("agricolae")
install.packages("bitops")
install.packages("RCurl")
install.packages("jsonlite")
install.packages("jSonarR")
install.packages("RJSONIO")
install.packages("biom")
install.packages("dunn.test")
install.packages("permute")
install.packages("ggplot2")
install.packages("lattice")
install.packages("lavaan")
install.packages("semPlot")
install.packages("sjPlot")
install.packages("vtreat")
install.packages("tidyr")
install.packages("knitr")
install.packages("rmarkdown")
install.packages("randomForest")
install.packages("rpart")
install.packages("randomForest")
install.packages("rgl")
install.packages("nortest")
install.packages("lmtest")
install.packages("leaps")
install.packages("aplpack")
install.packages("Rcmdr")
install.packages("RVAideMemoire")
install.packages("ecodist")
install.packages("adespatial")
source("https://bioconductor.org/biocLite.R")
biocLite("phyloseq")
library(phyloseq)
library(ancom.R)
library(devtools)
library(decontam)
library(vegan)
devtools::install_github("benjjneb/decontam")
library(decontam)
library(vegan)
library(parallel)
detectCores()
install_github("GuillemSalazar/FastaUtils")
library(FastaUtils)
install_github("zdk123/SpiecEasi")
library(SpiecEasi)
library(igraph)
library(splitstackshape)
library(plyr)
install.packages("splitstackshape")
library(splitstackshape)
library(adespatial)
install.packages("doParallel")
install.packages("DT")
install.packages("exactRankTests")
install.packages("foreach")
install.packages("ggplot2")
install.packages(“Rcpp”)
install.packages("shiny")
install.packages("foreach")
install.packages("foreach")
install.packages("ggplot2")
install.packages("Rcpp")
install.packages("shiny")
download.file("https://www.niehs.nih.gov/research/resources/software/biostatistics/ancom/ancom_software.zip",destfile = "ANCOM.zip")
setwd("/Users/jaspkaur/Google Drive/Metagenomics/pico_comb_run/pico")
library(phyloseq)
library(ancom.R)
library(devtools)
#devtools::install_github("benjjneb/decontam")
library(decontam)
library(vegan)
source("scripts/make_phyloseq.R")
source("scripts/root_phyloseq.R")
source("scripts/soil_phyloseq.R")
d.comb = merge_phyloseq(d_r, d_s)
d.comb
d.comb = subset_samples(d.comb, Pop_size != "Con")
d.comb = prune_taxa(taxa_sums(d.comb) > 0, d.comb)
seq_dep = estimate_richness(d.comb, measures = "Observed")
seq_dep$sequences = sample_sums(d.comb)
seq_dep = merge(sample_data(d.comb), seq_dep, by = "row.names")
sample_data(d.comb)$int = paste(sample_data(d.comb)$Source,".",sample_data(d.comb)$Population,".",sample_data(d.comb)$Year)
d.fin = subset_taxa(d.comb, Family == "f:Ceratobasidiaceae"|
Family == "f:Tulasnellaceae")
d.fin
met2 = data.frame(sample_data(d.fin))
env_met = met2[,cbind(1,2,3,4,5,6,7,8,9,10,11,37,38,39)]
env = met2[,12:36]
env = scale(env)
met3 = merge(env_met, env, by = "row.names")
row.names(met3) = met3$Row.names
d.fin = merge_phyloseq(tax_table(d.fin), otu_table(d.fin), sample_data(met3))
###identify the overlap between root and soil Otus
d.x = subset_taxa(d.fin, Family == "f:Tulasnellaceae")
d.x
d.r = subset_samples(d.fin, Source == "R")
d.r
d.r = prune_taxa(taxa_sums(d.r) >= 1, d.r)
d.r
d_r
